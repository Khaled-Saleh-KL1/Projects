{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bffd96a3-04ce-4e99-b573-7e0ba1d71a71",
   "metadata": {},
   "source": [
    "# Information Retrieval Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f3c1d-dd9f-4b69-8569-cab1d044b85f",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bea4e036-5e62-4fc4-b5ee-fbc93790e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import tqdm\n",
    "import warnings\n",
    "from tkinter import scrolledtext\n",
    "warnings.filterwarnings('ignore')\n",
    "corpus = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b2894-0e3f-4007-aabd-eecba9d572ec",
   "metadata": {},
   "source": [
    "## 2. Downloading Necessary NLTK Data Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "11809b56-cec3-48d4-8032-8a893fab4f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\96279\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\96279\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\96279\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf867457-f727-425b-85a1-661417c73b20",
   "metadata": {},
   "source": [
    "## 3. Importing Corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a288af2c-2457-499d-a3fe-065c37be4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad58a7c-647a-4ec3-b9ca-3efa4f5ae9e4",
   "metadata": {},
   "source": [
    "# **`Phase 1`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c450748-483b-46de-a57a-7da0c23ffb8d",
   "metadata": {},
   "source": [
    "## 4. Removing Punctuations From Documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cf682edd-c274-47a4-ba9e-7c8ea16935fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):   \n",
    "    result = ''\n",
    "    \n",
    "    for i, letter in enumerate(text):\n",
    "        if letter in '<>#!$%^&*()+-/*\\n\\t:,][}{\"\\'':\n",
    "            result += ' '\n",
    "        elif letter == '.' and ( i == len(text) - 1 or text[i+1] in '\\n\\t '):\n",
    "            continue\n",
    "        else:\n",
    "            result += letter\n",
    "\n",
    "    return result.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58d571-8a67-42ba-a309-41e3202223a1",
   "metadata": {},
   "source": [
    "## 5. Stemming Words Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5a40da3b-cc33-4b7a-9fad-b2aef3ede329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(corpus):\n",
    "    result = []\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    for file in corpus:\n",
    "        stemmed_file = ''\n",
    "        file = remove_punctuations(file)\n",
    "        stemmed_words = [stemmer.stem(word) for word in file.split()]\n",
    "        result.append(' '.join(stemmed_words))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe05fa2-3dd3-4969-a157-9dee649be650",
   "metadata": {},
   "source": [
    "## 6. Lemmitizing Words Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0850fab5-9df0-4007-9574-23e82b8e1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(corpus):\n",
    "    result = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for file in corpus:\n",
    "        lemmatized_file = ''\n",
    "        file = remove_punctuations(file)\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in file.split()]\n",
    "        lemmatized_file = ' '.join(lemmatized_words)\n",
    "        result.append(lemmatized_file)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7715122-8124-48ae-96e4-8112137cf7ff",
   "metadata": {},
   "source": [
    "## 7. Constructing Inverted Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "354b7230-27de-4773-8aaa-76adfe96c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing(corpus):\n",
    "    index = dict()\n",
    "    \n",
    "    for file_index, text in enumerate(corpus):\n",
    "        for word in text.split(): \n",
    "            if word in index.keys():\n",
    "                index[word].add(file_index)\n",
    "            else:\n",
    "                index[word] = {file_index}        \n",
    "        \n",
    "    return dict(sorted(index.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8347c-c237-4d48-b621-1ed067de89a2",
   "metadata": {},
   "source": [
    "## 8. Applying Previous Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "67082172-c36a-4db1-a484-152d32c8bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmed_corpus = stemming(corpus.data)\n",
    "#index = indexing(stemmed_corpus)\n",
    "## -------------------------------------\n",
    "lemmatizing_corpus = lemmatizing(corpus.data)\n",
    "index = indexing(lemmatizing_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb8adb-ba13-4669-a046-5ff6e721540d",
   "metadata": {},
   "source": [
    "# **`Phase 2`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287070da-e207-41f8-911c-20246e1835be",
   "metadata": {},
   "source": [
    "# 1. Pre-processing Query: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "544ed1bb-f3ed-4548-b831-eb9a8bb25342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    \n",
    "    query = app.user_query\n",
    "    query = remove_punctuations(query)\n",
    "    #query = stemming(query.split())\n",
    "    query = lemmatizing(query.split())\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37c8a4-aa01-4482-8025-5fd96434cd2a",
   "metadata": {},
   "source": [
    "## 2. Searching Inverted Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "75909c62-146a-4160-a8a8-6a66b75b3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(query):  \n",
    "    \n",
    "    resulted_docs = []\n",
    "    \n",
    "    for word in query:     \n",
    "        if word in index.keys():\n",
    "            resulted_docs.append(index[word])   \n",
    "        else: \n",
    "            return []\n",
    "\n",
    "    return resulted_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ba2f6c-a99d-4b12-ac1a-eb8c63939fd3",
   "metadata": {},
   "source": [
    "## 3. Merging Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fc7edd99-86ee-4b2f-9460-5e4e965f95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(files):\n",
    "\n",
    "    if files == []:\n",
    "        return None\n",
    "        \n",
    "    files = [sorted(list(word_file)) for word_file in files]\n",
    "    files = sorted(files, key=len)\n",
    "\n",
    "    final_results = files[0]\n",
    "    \n",
    "    for i in files[1:]: \n",
    "        final_results = [element for element in final_results if element in i]\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d629ef15-45c9-4aac-a099-b19fa9098786",
   "metadata": {},
   "source": [
    "## 4. Graphical User Interface (GUI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e2464a32-a871-44f7-ae4c-f18f0c5d4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GUI_result(docs):\n",
    "\n",
    "    if docs == None or len(docs) == 0:\n",
    "        return \"No Relevant Documents.\\n\"\n",
    "        \n",
    "    string =  f'Document ID: '\n",
    "    for i in docs:\n",
    "        \n",
    "        string += f'{i}, '\n",
    "\n",
    "    string += '\\nThank You For Using Our System.'\n",
    "        \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "099d6a31-c224-4e00-b3e7-39d55a95b52e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BasicIRSystemGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Basic Information Retrieval System\")\n",
    "        \n",
    "        self.label = tk.Label(root, text=\"Enter your query:\")\n",
    "        self.label.pack(pady=10)\n",
    "        \n",
    "        self.query_entry = tk.Entry(root, width=50)\n",
    "        self.query_entry.pack(pady=10)\n",
    "        \n",
    "        self.search_button = tk.Button(root, text=\"Search\", command=self.search)\n",
    "        self.search_button.pack(pady=10)\n",
    "        \n",
    "        self.result_text = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=70, height=40)\n",
    "        self.result_text.pack(pady=10)\n",
    "        \n",
    "    \n",
    "    def search(self):\n",
    "        self.user_query = self.query_entry.get()\n",
    "\n",
    "        self.result_text.delete(1.0, tk.END)  # Clear previous results\n",
    "        self.result_text.insert(tk.INSERT, GUI_result(merge(search_index(preprocess_query(self.user_query)))))\n",
    "\n",
    "root = tk.Tk()\n",
    "app = BasicIRSystemGUI(root)\n",
    "_ = root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233114b1-6abe-4bef-a518-562b35f239b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
